#!/usr/bin/env python2
# vim:fileencoding=utf-8
from __future__ import unicode_literals, division, absolute_import, print_function
from calibre.web.feeds.news import BasicNewsRecipe

from collections import defaultdict


def classes(classes):
    q = frozenset(classes.split(' '))
    return dict(
        attrs={'class': lambda x: x and frozenset(x.split()).intersection(q)}
    )


class RockPaperShotgun(BasicNewsRecipe):
    title = 'Rock Paper Shotgun'
    oldest_article = 7
    max_articles_per_feed = 30
    auto_cleanup = False
    no_stylesheets = True
    keep_only_tags = [
        dict(name='h1', attrs={'class':'title'}),
        dict(name='span', attrs={'class':'strapline'}),
        dict(name='div', attrs={'class':'headline_asset'}),
        dict(name='div', attrs={'class':'article_body'}),
    ]
    remove_tags = []
    
    def parse_index(self):

        index_urls = ('https://www.rockpapershotgun.com/latest','https://www.rockpapershotgun.com/latest?page=2','https://www.rockpapershotgun.com/latest?page=3')

        feeds = defaultdict(list)

        for index_url in index_urls:
            soup = self.index_to_soup(index_url)

            for articlesoup in soup.find_all('article', class_="summary"):
                
                #inspect(article.contents)
                articles = []

                section = articlesoup.attrs['data-article-type'].strip().capitalize()
                title = articlesoup.find('a')['title']
                url = articlesoup.find('a')['href']
                description = articlesoup.find('div', class_="excerpt").text.strip()

                feeds[section].append({'title': title, 'url': url, 'description': description})
        
        ans = []
        for sec in sorted(feeds, key=lambda x: (x != 'Cover Story', x)):
            articles = feeds[sec]
            if articles:
                ans.append((sec, articles))
        return ans
